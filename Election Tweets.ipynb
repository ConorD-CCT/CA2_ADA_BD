{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50c4ff1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf, to_date\n",
    "from pyspark.sql.types import FloatType\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41299c48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.2.15:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if Spark is running\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90b96987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "filename = '2016_US_election_tweets.csv'\n",
    "\n",
    "# Read input file from hadoop directory and convert to pandas\n",
    "df = spark.read.csv('/user1/CA2/'+filename,header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eef35ac0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.select('candidate_id', \"created_at\", \"tweet_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "304c1eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+--------------------+\n",
      "|       candidate_id|         created_at|          tweet_text|\n",
      "+-------------------+-------------------+--------------------+\n",
      "|                  1|2016-08-30 14:41:22|@zitto007 @Matthe...|\n",
      "|                  1|2016-08-30 14:41:22|I think @HumaAbed...|\n",
      "|                  1|2016-08-30 14:41:24|                null|\n",
      "|                  1|2016-08-30 14:41:25|                null|\n",
      "|                  1|2016-08-30 14:41:25|                null|\n",
      "|                  1|2016-08-30 14:41:25|                null|\n",
      "|                  1|2016-08-30 14:41:25|@HillaryClinton @...|\n",
      "|                  1|2016-08-30 14:41:26|                null|\n",
      "|                  1|2016-08-30 14:41:26|                null|\n",
      "|                  3|2016-08-30 14:41:27|                null|\n",
      "|                  1|2016-08-30 14:41:28|@HillaryClinton @...|\n",
      "|                  1|2016-08-30 14:41:29|                null|\n",
      "|                  3|2016-08-30 14:41:31|@BrinckJeff @POTU...|\n",
      "|                  1|2016-08-30 14:41:31|                null|\n",
      "|                  1|2016-08-30 14:41:32|                null|\n",
      "|                  1|2016-08-30 14:41:32|                null|\n",
      "|                  1|               null|@realDonaldTrump ...|\n",
      "|               null|               null|                null|\n",
      "|2016-08-30 14:41:32|               null|                null|\n",
      "|                  3|2016-08-30 14:41:32|        @BarackObama|\n",
      "+-------------------+-------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96557282",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_nulls = df.na.drop()\n",
    "tweets = df_no_nulls.filter(df.candidate_id < 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2d8dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "521f4611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+------------------------------------------------------------+\n",
      "|candidate_id|         created_at|                                                  tweet_text|\n",
      "+------------+-------------------+------------------------------------------------------------+\n",
      "|           1|2016-08-30 14:41:22|@zitto007 @MatthewHrenak @FoxNews @HillaryClinton And you...|\n",
      "|           1|2016-08-30 14:41:22|I think @HumaAbedin should be ashamed that she didn't sta...|\n",
      "|           1|2016-08-30 14:41:25|@HillaryClinton @realDonaldTrump @CNN #trumpPence16 https...|\n",
      "|           1|2016-08-30 14:41:28|@HillaryClinton @Comeridethwhale so are you! trump &amp; ...|\n",
      "|           1|2016-08-30 14:41:33|@HillaryClinton https://t.co/pgck0ifrzC atleast @realDona...|\n",
      "|           1|2016-08-30 14:41:33|Working people: @HillaryClinton, not @realDonaldTrump, is...|\n",
      "|           1|2016-08-30 14:41:34|@FoxNews no, @JohnKerry the media needs 2 stop covering u...|\n",
      "|           1|2016-08-30 14:41:36|#NYTimes getting a quote from #Trump on how #Weiner divor...|\n",
      "|           1|2016-08-30 14:41:36|Working people: @HillaryClinton, not @realDonaldTrump, is...|\n",
      "|           1|2016-08-30 14:41:36|                         squad goals https://t.co/sPssovyBDt|\n",
      "|           1|2016-08-30 14:41:36|THIS was the point of @HillaryClinton's alt-right speech:...|\n",
      "|           1|2016-08-30 14:41:37|@Deathc0de @JamesPMorrison @HillaryClinton sure he was! @...|\n",
      "|           1|2016-08-30 14:41:37|@craigmelvin Is it a crime now for @HillaryClinton to rai...|\n",
      "|           1|2016-08-30 14:41:38|@Reince @HillaryClinton SO why do YOU care? Keep your FLI...|\n",
      "|           1|2016-08-30 14:41:39|      @Marycar08639249 @HillaryClinton Have fun with Donnie.|\n",
      "|           1|2016-08-30 14:41:40|@sarahleahwolfe @finkd @MSNBC @HillaryClinton Well, she h...|\n",
      "|           1|2016-08-30 14:41:41|                                             @HillaryClinton|\n",
      "|           1|2016-08-30 14:41:41|Won't help her really. If @SenSanders begged me personall...|\n",
      "|           1|2016-08-30 14:41:41|I'm proud to be on Team @HillaryClinton. You should join,...|\n",
      "|           1|2016-08-30 14:41:41|.@HillaryClinton We need federal laws for severe animal a...|\n",
      "+------------+-------------------+------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets.show(truncate=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "012695a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.analyze_sentiment(text)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyze_sentiment(text):\n",
    "    return analyzer.polarity_scores(text)[\"compound\"]\n",
    "\n",
    "sentiment_udf = udf(analyze_sentiment, FloatType())\n",
    "spark.udf.register(\"sentiment_udf\", sentiment_udf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "523e5d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp to date\n",
    "tweets = tweets.withColumn(\"date\", to_date(col(\"created_at\")))\n",
    "\n",
    "# Calculate sentiment score for each tweet\n",
    "tweets = tweets.withColumn(\"sentiment\", sentiment_udf(col(\"tweet_text\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0c2c5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+----------------------------------------+----------+---------+\n",
      "|candidate_id|         created_at|                              tweet_text|      date|sentiment|\n",
      "+------------+-------------------+----------------------------------------+----------+---------+\n",
      "|           1|2016-08-30 14:41:22|@zitto007 @MatthewHrenak @FoxNews @Hi...|2016-08-30|  -0.6166|\n",
      "|           1|2016-08-30 14:41:22|I think @HumaAbedin should be ashamed...|2016-08-30|  -0.5994|\n",
      "|           1|2016-08-30 14:41:25|@HillaryClinton @realDonaldTrump @CNN...|2016-08-30|      0.0|\n",
      "|           1|2016-08-30 14:41:28|@HillaryClinton @Comeridethwhale so a...|2016-08-30|  -0.8016|\n",
      "|           1|2016-08-30 14:41:33|@HillaryClinton https://t.co/pgck0ifr...|2016-08-30|    -0.75|\n",
      "|           1|2016-08-30 14:41:33|Working people: @HillaryClinton, not ...|2016-08-30|   0.3818|\n",
      "|           1|2016-08-30 14:41:34|@FoxNews no, @JohnKerry the media nee...|2016-08-30|  -0.7783|\n",
      "|           1|2016-08-30 14:41:36|#NYTimes getting a quote from #Trump ...|2016-08-30|      0.0|\n",
      "|           1|2016-08-30 14:41:36|Working people: @HillaryClinton, not ...|2016-08-30|   0.3818|\n",
      "|           1|2016-08-30 14:41:36|     squad goals https://t.co/sPssovyBDt|2016-08-30|      0.0|\n",
      "|           1|2016-08-30 14:41:36|THIS was the point of @HillaryClinton...|2016-08-30|      0.0|\n",
      "|           1|2016-08-30 14:41:37|@Deathc0de @JamesPMorrison @HillaryCl...|2016-08-30|   0.6114|\n",
      "|           1|2016-08-30 14:41:37|@craigmelvin Is it a crime now for @H...|2016-08-30|  -0.2714|\n",
      "|           1|2016-08-30 14:41:38|@Reince @HillaryClinton SO why do YOU...|2016-08-30|  -0.1759|\n",
      "|           1|2016-08-30 14:41:39|@Marycar08639249 @HillaryClinton Have...|2016-08-30|   0.5106|\n",
      "|           1|2016-08-30 14:41:40|@sarahleahwolfe @finkd @MSNBC @Hillar...|2016-08-30|   0.2732|\n",
      "|           1|2016-08-30 14:41:41|                         @HillaryClinton|2016-08-30|      0.0|\n",
      "|           1|2016-08-30 14:41:41|Won't help her really. If @SenSanders...|2016-08-30|  -0.3089|\n",
      "|           1|2016-08-30 14:41:41|I'm proud to be on Team @HillaryClint...|2016-08-30|     0.68|\n",
      "|           1|2016-08-30 14:41:41|.@HillaryClinton We need federal laws...|2016-08-30|  -0.8834|\n",
      "+------------+-------------------+----------------------------------------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "tweets.show(truncate=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea80378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e648d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-08 18:56:54,331 ERROR executor.Executor: Exception in task 43.0 in stage 8.0 (TID 155)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.util.Arrays.copyOf(Arrays.java:3236)\n",
      "\tat java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)\n",
      "\tat java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)\n",
      "\tat java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)\n",
      "\tat org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)\n",
      "\tat java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)\n",
      "\tat java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)\n",
      "\tat org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:242)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:53)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult$$Lambda$2504/1746259086.apply$mcV$sp(Unknown Source)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1457)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:51)\n",
      "\tat java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)\n",
      "\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)\n",
      "\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n",
      "\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n",
      "\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:44)\n",
      "\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:101)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:615)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "2023-05-08 18:56:54,357 ERROR util.SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 43.0 in stage 8.0 (TID 155),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.util.Arrays.copyOf(Arrays.java:3236)\n",
      "\tat java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)\n",
      "\tat java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)\n",
      "\tat java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)\n",
      "\tat org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)\n",
      "\tat java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)\n",
      "\tat java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)\n",
      "\tat org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:242)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:53)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult$$Lambda$2504/1746259086.apply$mcV$sp(Unknown Source)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1457)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:51)\n",
      "\tat java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)\n",
      "\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)\n",
      "\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n",
      "\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n",
      "\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:44)\n",
      "\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:101)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:615)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "2023-05-08 18:56:54,387 WARN scheduler.TaskSetManager: Lost task 43.0 in stage 8.0 (TID 155) (10.0.2.15 executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.util.Arrays.copyOf(Arrays.java:3236)\n",
      "\tat java.io.ByteArrayOutputStream.grow(ByteArrayOutputStream.java:118)\n",
      "\tat java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:93)\n",
      "\tat java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:153)\n",
      "\tat org.apache.spark.util.ByteBufferOutputStream.write(ByteBufferOutputStream.scala:41)\n",
      "\tat java.io.ObjectOutputStream$BlockDataOutputStream.write(ObjectOutputStream.java:1853)\n",
      "\tat java.io.ObjectOutputStream.write(ObjectOutputStream.java:709)\n",
      "\tat org.apache.spark.util.Utils$.writeByteBuffer(Utils.scala:242)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.$anonfun$writeExternal$1(TaskResult.scala:53)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult$$Lambda$2504/1746259086.apply$mcV$sp(Unknown Source)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1457)\n",
      "\tat org.apache.spark.scheduler.DirectTaskResult.writeExternal(TaskResult.scala:51)\n",
      "\tat java.io.ObjectOutputStream.writeExternalData(ObjectOutputStream.java:1459)\n",
      "\tat java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1430)\n",
      "\tat java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1178)\n",
      "\tat java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:348)\n",
      "\tat org.apache.spark.serializer.JavaSerializationStream.writeObject(JavaSerializer.scala:44)\n",
      "\tat org.apache.spark.serializer.JavaSerializerInstance.serialize(JavaSerializer.scala:101)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:615)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "2023-05-08 18:56:54,391 ERROR scheduler.TaskSetManager: Task 43 in stage 8.0 failed 1 times; aborting job\n",
      "2023-05-08 18:56:54,465 WARN scheduler.TaskSetManager: Lost task 44.0 in stage 8.0 (TID 156) (10.0.2.15 executor driver): TaskKilled (Stage cancelled)\n",
      "----------------------------------------                         (43 + 3) / 106]\n",
      "Exception occurred during processing of request from ('127.0.0.1', 48084)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 262, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 235, in poll\n",
      "    if func():\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 239, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"/usr/local/spark/python/pyspark/serializers.py\", line 564, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "time_based_sentiment = tweets.groupBy(\"candidate_id\", \"date\") \\\n",
    "    .mean(\"sentiment\") \\\n",
    "    .withColumnRenamed(\"avg(sentiment)\", \"sentiment\") \\\n",
    "    .orderBy(\"candidate_id\", \"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ab125c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_based_sentiment.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d56cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7dc512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b29c524",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = time_based_sentiment.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfdcb96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
